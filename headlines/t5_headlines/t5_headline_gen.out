Downloading config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]Downloading config.json: 100%|██████████| 1.24k/1.24k [00:00<00:00, 247kB/s]
Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|          | 10.5M/892M [00:00<00:25, 34.1MB/s]Downloading pytorch_model.bin:   2%|▏         | 21.0M/892M [00:00<00:29, 29.6MB/s]Downloading pytorch_model.bin:   4%|▎         | 31.5M/892M [00:00<00:26, 32.2MB/s]Downloading pytorch_model.bin:   5%|▍         | 41.9M/892M [00:01<00:35, 24.1MB/s]Downloading pytorch_model.bin:   6%|▌         | 52.4M/892M [00:01<00:31, 26.4MB/s]Downloading pytorch_model.bin:   7%|▋         | 62.9M/892M [00:02<00:27, 30.0MB/s]Downloading pytorch_model.bin:   8%|▊         | 73.4M/892M [00:02<00:27, 30.2MB/s]Downloading pytorch_model.bin:   9%|▉         | 83.9M/892M [00:02<00:26, 29.9MB/s]Downloading pytorch_model.bin:  11%|█         | 94.4M/892M [00:03<00:26, 30.4MB/s]Downloading pytorch_model.bin:  12%|█▏        | 105M/892M [00:03<00:22, 35.6MB/s] Downloading pytorch_model.bin:  13%|█▎        | 115M/892M [00:03<00:21, 35.8MB/s]Downloading pytorch_model.bin:  14%|█▍        | 126M/892M [00:04<00:26, 28.7MB/s]Downloading pytorch_model.bin:  15%|█▌        | 136M/892M [00:04<00:34, 22.2MB/s]Downloading pytorch_model.bin:  16%|█▋        | 147M/892M [00:05<00:28, 25.8MB/s]Downloading pytorch_model.bin:  18%|█▊        | 157M/892M [00:05<00:29, 25.0MB/s]Downloading pytorch_model.bin:  19%|█▉        | 168M/892M [00:06<00:33, 21.9MB/s]Downloading pytorch_model.bin:  20%|█▉        | 178M/892M [00:06<00:35, 19.8MB/s]Downloading pytorch_model.bin:  21%|██        | 189M/892M [00:07<00:31, 22.4MB/s]Downloading pytorch_model.bin:  22%|██▏       | 199M/892M [00:07<00:28, 24.3MB/s]Downloading pytorch_model.bin:  24%|██▎       | 210M/892M [00:07<00:27, 24.7MB/s]Downloading pytorch_model.bin:  25%|██▍       | 220M/892M [00:08<00:22, 30.4MB/s]Downloading pytorch_model.bin:  26%|██▌       | 231M/892M [00:08<00:24, 27.1MB/s]Downloading pytorch_model.bin:  27%|██▋       | 241M/892M [00:08<00:22, 28.4MB/s]Downloading pytorch_model.bin:  28%|██▊       | 252M/892M [00:09<00:24, 26.3MB/s]Downloading pytorch_model.bin:  29%|██▉       | 262M/892M [00:09<00:20, 30.2MB/s]Downloading pytorch_model.bin:  31%|███       | 273M/892M [00:09<00:20, 31.0MB/s]Downloading pytorch_model.bin:  32%|███▏      | 283M/892M [00:10<00:17, 34.0MB/s]Downloading pytorch_model.bin:  33%|███▎      | 294M/892M [00:10<00:21, 27.4MB/s]Downloading pytorch_model.bin:  34%|███▍      | 304M/892M [00:10<00:18, 31.1MB/s]Downloading pytorch_model.bin:  35%|███▌      | 315M/892M [00:11<00:17, 32.5MB/s]Downloading pytorch_model.bin:  36%|███▋      | 325M/892M [00:11<00:17, 33.3MB/s]Downloading pytorch_model.bin:  38%|███▊      | 336M/892M [00:12<00:20, 26.9MB/s]Downloading pytorch_model.bin:  39%|███▉      | 346M/892M [00:12<00:18, 29.6MB/s]Downloading pytorch_model.bin:  40%|███▉      | 357M/892M [00:12<00:15, 34.8MB/s]Downloading pytorch_model.bin:  41%|████      | 367M/892M [00:12<00:15, 34.4MB/s]Downloading pytorch_model.bin:  42%|████▏     | 377M/892M [00:13<00:20, 25.5MB/s]Downloading pytorch_model.bin:  44%|████▎     | 388M/892M [00:13<00:17, 28.8MB/s]Downloading pytorch_model.bin:  45%|████▍     | 398M/892M [00:14<00:16, 30.6MB/s]Downloading pytorch_model.bin:  46%|████▌     | 409M/892M [00:14<00:16, 28.9MB/s]Downloading pytorch_model.bin:  47%|████▋     | 419M/892M [00:14<00:16, 27.9MB/s]Downloading pytorch_model.bin:  48%|████▊     | 430M/892M [00:15<00:15, 30.4MB/s]Downloading pytorch_model.bin:  49%|████▉     | 440M/892M [00:15<00:15, 29.7MB/s]Downloading pytorch_model.bin:  51%|█████     | 451M/892M [00:15<00:13, 31.5MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 461M/892M [00:16<00:17, 24.0MB/s]Downloading pytorch_model.bin:  53%|█████▎    | 472M/892M [00:16<00:15, 26.6MB/s]Downloading pytorch_model.bin:  54%|█████▍    | 482M/892M [00:17<00:13, 30.2MB/s]Downloading pytorch_model.bin:  55%|█████▌    | 493M/892M [00:17<00:14, 27.5MB/s]Downloading pytorch_model.bin:  56%|█████▋    | 503M/892M [00:18<00:15, 24.3MB/s]Downloading pytorch_model.bin:  58%|█████▊    | 514M/892M [00:18<00:14, 26.4MB/s]Downloading pytorch_model.bin:  59%|█████▉    | 524M/892M [00:18<00:11, 31.8MB/s]Downloading pytorch_model.bin:  60%|█████▉    | 535M/892M [00:18<00:09, 36.2MB/s]Downloading pytorch_model.bin:  61%|██████    | 545M/892M [00:19<00:11, 31.4MB/s]Downloading pytorch_model.bin:  62%|██████▏   | 556M/892M [00:19<00:10, 31.3MB/s]Downloading pytorch_model.bin:  64%|██████▎   | 566M/892M [00:19<00:09, 34.4MB/s]Downloading pytorch_model.bin:  65%|██████▍   | 577M/892M [00:20<00:09, 34.0MB/s]Downloading pytorch_model.bin:  66%|██████▌   | 587M/892M [00:20<00:10, 28.0MB/s]Downloading pytorch_model.bin:  67%|██████▋   | 598M/892M [00:20<00:10, 28.0MB/s]Downloading pytorch_model.bin:  68%|██████▊   | 608M/892M [00:21<00:09, 30.6MB/s]Downloading pytorch_model.bin:  69%|██████▉   | 619M/892M [00:21<00:09, 29.3MB/s]Downloading pytorch_model.bin:  71%|███████   | 629M/892M [00:22<00:10, 24.4MB/s]Downloading pytorch_model.bin:  72%|███████▏  | 640M/892M [00:22<00:09, 26.2MB/s]Downloading pytorch_model.bin:  73%|███████▎  | 650M/892M [00:22<00:07, 31.3MB/s]Downloading pytorch_model.bin:  74%|███████▍  | 661M/892M [00:23<00:07, 30.9MB/s]Downloading pytorch_model.bin:  75%|███████▌  | 671M/892M [00:23<00:09, 23.3MB/s]Downloading pytorch_model.bin:  76%|███████▋  | 682M/892M [00:24<00:07, 27.3MB/s]Downloading pytorch_model.bin:  78%|███████▊  | 692M/892M [00:24<00:05, 33.6MB/s]Downloading pytorch_model.bin:  79%|███████▉  | 703M/892M [00:24<00:05, 35.2MB/s]Downloading pytorch_model.bin:  80%|███████▉  | 713M/892M [00:25<00:08, 21.8MB/s]Downloading pytorch_model.bin:  81%|████████  | 724M/892M [00:25<00:06, 26.2MB/s]Downloading pytorch_model.bin:  82%|████████▏ | 734M/892M [00:25<00:05, 30.6MB/s]Downloading pytorch_model.bin:  83%|████████▎ | 744M/892M [00:26<00:04, 30.6MB/s]Downloading pytorch_model.bin:  85%|████████▍ | 755M/892M [00:26<00:05, 26.3MB/s]Downloading pytorch_model.bin:  86%|████████▌ | 765M/892M [00:26<00:04, 27.8MB/s]Downloading pytorch_model.bin:  87%|████████▋ | 776M/892M [00:27<00:03, 30.5MB/s]Downloading pytorch_model.bin:  89%|████████▉ | 797M/892M [00:27<00:02, 33.1MB/s]Downloading pytorch_model.bin:  91%|█████████ | 807M/892M [00:28<00:02, 34.6MB/s]Downloading pytorch_model.bin:  92%|█████████▏| 818M/892M [00:28<00:02, 33.4MB/s]Downloading pytorch_model.bin:  93%|█████████▎| 828M/892M [00:28<00:01, 36.4MB/s]Downloading pytorch_model.bin:  94%|█████████▍| 839M/892M [00:29<00:01, 27.3MB/s]Downloading pytorch_model.bin:  95%|█████████▌| 849M/892M [00:29<00:01, 28.6MB/s]Downloading pytorch_model.bin:  96%|█████████▋| 860M/892M [00:29<00:01, 28.3MB/s]Downloading pytorch_model.bin:  98%|█████████▊| 870M/892M [00:30<00:00, 28.7MB/s]Downloading pytorch_model.bin:  99%|█████████▉| 881M/892M [00:30<00:00, 24.7MB/s]Downloading pytorch_model.bin: 100%|█████████▉| 891M/892M [00:31<00:00, 28.4MB/s]Downloading pytorch_model.bin: 100%|██████████| 892M/892M [00:31<00:00, 28.3MB/s]
Downloading tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]Downloading tokenizer_config.json: 100%|██████████| 43.0/43.0 [00:00<00:00, 27.0kB/s]
Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 38.2MB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 1.79k/1.79k [00:00<00:00, 1.14MB/s]
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 512). Running this sequence through the model will result in indexing errors
>> Results dumped to t5 folder!
